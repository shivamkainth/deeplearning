{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST_with_tensorflow.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"tQH8VMZJa_F4","colab_type":"code","colab":{}},"source":["#import necessary libraries\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xrRGAz3Na_Hc","colab_type":"text"},"source":["### Reading and Visualizing the MNIST Dataset"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"TNYgCr7ta_Hc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":92},"outputId":"75d42a1a-b5d0-41b5-b126-458bb1a98b9b","executionInfo":{"status":"ok","timestamp":1559063555400,"user_tz":0,"elapsed":1700,"user":{"displayName":"Shivam Kainth","photoUrl":"","userId":"09166769347498440747"}}},"source":["# Import MNIST data\n","import warnings\n","warnings.filterwarnings('ignore')\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Extracting /tmp/data/train-images-idx3-ubyte.gz\n","Extracting /tmp/data/train-labels-idx1-ubyte.gz\n","Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n","Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vzDxIbCGa_Hc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"fc05acd3-a599-43d3-c3b1-c6d4d7a45104","executionInfo":{"status":"ok","timestamp":1559063563300,"user_tz":0,"elapsed":1300,"user":{"displayName":"Shivam Kainth","photoUrl":"","userId":"09166769347498440747"}}},"source":["print (mnist.train.num_examples)\n","print (mnist.train.images.shape)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["55000\n","(55000, 784)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QSqKfmS2a_Hc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"d5e11f77-1e1b-4bf7-c581-cce57d583c54","executionInfo":{"status":"ok","timestamp":1559063567300,"user_tz":0,"elapsed":1200,"user":{"displayName":"Shivam Kainth","photoUrl":"","userId":"09166769347498440747"}}},"source":["mnist.train.images[0].shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(784,)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"UyKqpJWLa_JA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":112},"outputId":"64b6fe4d-37f7-4a18-8662-19a01817d5dc","executionInfo":{"status":"ok","timestamp":1559063571900,"user_tz":0,"elapsed":1200,"user":{"displayName":"Shivam Kainth","photoUrl":"","userId":"09166769347498440747"}}},"source":["# Determine the (random) indexes of the images that you want to see \n","digit_indices_to_print = [300, 2250, 3600, 4000]\n","\n","# Fill out the subplots with the random images that you defined \n","for i in range(len(digit_indices_to_print)):\n","    plt.subplot(1, 4, i+1)\n","    plt.axis('off')\n","    plt.imshow(mnist.train.images[digit_indices_to_print[i]].reshape(28,28),cmap=plt.cm.binary)\n","    plt.subplots_adjust(wspace=0.5)\n","\n","plt.show()"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXAAAABfCAYAAADxlJxoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n","text/plain":["<Figure size 432x288 with 4 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"sra6RP5La_JA","colab_type":"text"},"source":["### Setting up the hyperparameters"]},{"cell_type":"code","metadata":{"id":"xSKU4NGpa_JA","colab_type":"code","colab":{}},"source":["# Parameters\n","learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 100\n","display_step = 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M5tmG4eGa_JA","colab_type":"text"},"source":["### Initializing the network parameters"]},{"cell_type":"code","metadata":{"id":"SkdkmuNDa_JA","colab_type":"code","colab":{}},"source":["# Network Parameters\n","n_hidden_1 = 256 # 1st layer number of neurons\n","n_hidden_2 = 256 # 2nd layer number of neurons\n","n_input = 784 # MNIST data input (img shape: 28*28)\n","n_classes = 10 # MNIST total classes (0-9 digits)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uyIZtFMqa_JA","colab_type":"text"},"source":["### Let's define the Placeholders"]},{"cell_type":"code","metadata":{"id":"JwAt7eMTa_JA","colab_type":"code","colab":{}},"source":["# tf Graph input\n","X = tf.placeholder(\"float\", [None, n_input])\n","Y = tf.placeholder(\"float\", [None, n_classes])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bihOVcBWa_JA","colab_type":"text"},"source":["### Setting up Weights and Biases of the whole network"]},{"cell_type":"code","metadata":{"id":"B36qhGFca_JA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":93},"outputId":"30774d02-c0ec-43f6-fd7f-9d8100458377","executionInfo":{"status":"ok","timestamp":1559063599700,"user_tz":0,"elapsed":1400,"user":{"displayName":"Shivam Kainth","photoUrl":"","userId":"09166769347498440747"}}},"source":["# Store layers weight & bias\n","weights = {\n","    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n","    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n","    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n","}\n","biases = {\n","    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n","    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n","    'out': tf.Variable(tf.random_normal([n_classes]))\n","}"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mL9mxBwJa_JA","colab_type":"text"},"source":["### Let's define the MLP now"]},{"cell_type":"code","metadata":{"id":"7EQwUSgea_JA","colab_type":"code","colab":{}},"source":["# Create model\n","def multilayer_perceptron(x):\n","    # Hidden fully connected layer with 256 neurons\n","    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n","    # Hidden fully connected layer with 256 neurons\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n","    # Output fully connected layer with a neuron for each class\n","    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n","    return out_layer"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NbiHSGpga_JA","colab_type":"text"},"source":["### Defining Model, Loss and Optimizer"]},{"cell_type":"code","metadata":{"id":"HlPPxE1Fa_JA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"bfd5d0bd-5cbe-4d2d-e21e-5afa3cba0d91","executionInfo":{"status":"ok","timestamp":1559063610600,"user_tz":0,"elapsed":1300,"user":{"displayName":"Shivam Kainth","photoUrl":"","userId":"09166769347498440747"}}},"source":["# Construct model\n","logits = multilayer_perceptron(X)\n","\n","# Define loss and optimizer\n","loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n","    logits=logits, labels=Y))\n","\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","\n","train_op = optimizer.minimize(loss_op)\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-12-9f287fb9883a>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"leLvRoUUa_Kk","colab_type":"text"},"source":["### Let's train the model"]},{"cell_type":"code","metadata":{"id":"jqo41W1Pa_Kk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":335},"outputId":"012009f8-787c-458d-f30e-a72d13c003aa","executionInfo":{"status":"ok","timestamp":1559063665700,"user_tz":0,"elapsed":39500,"user":{"displayName":"Shivam Kainth","photoUrl":"","userId":"09166769347498440747"}}},"source":["# Initializing the variables\n","init = tf.global_variables_initializer()\n","\n","with tf.Session() as sess:\n","    sess.run(init)\n","\n","    # Training cycle\n","    for epoch in range(training_epochs):\n","        avg_cost = 0.\n","        total_batch = int(mnist.train.num_examples/batch_size)\n","        # Loop over all batches\n","        for i in range(total_batch):\n","            batch_x, batch_y = mnist.train.next_batch(batch_size)\n","            # Run optimization op (backprop) and cost op (to get loss value)\n","            _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x,\n","                                                            Y: batch_y})\n","            # Compute average loss\n","            avg_cost += c / total_batch\n","        # Display logs per epoch step\n","        if epoch % display_step == 0:\n","            print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n","    print(\"Optimization Finished!\")\n","\n","    # Test model\n","    pred = tf.nn.softmax(logits)  # Apply softmax to logits\n","    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n","    # Calculate accuracy\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n","    print(\"Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch: 0001 cost=356.221824681\n","Epoch: 0002 cost=95.192530257\n","Epoch: 0003 cost=71.160221480\n","Epoch: 0004 cost=58.498976049\n","Epoch: 0005 cost=50.087859576\n","Epoch: 0006 cost=44.537599174\n","Epoch: 0007 cost=39.035336980\n","Epoch: 0008 cost=35.796860128\n","Epoch: 0009 cost=32.720397322\n","Epoch: 0010 cost=30.357062924\n","Epoch: 0011 cost=27.993972609\n","Epoch: 0012 cost=25.851314588\n","Epoch: 0013 cost=24.785568114\n","Epoch: 0014 cost=24.378865424\n","Epoch: 0015 cost=22.235343107\n","Optimization Finished!\n","Accuracy: 0.8876\n"],"name":"stdout"}]}]}